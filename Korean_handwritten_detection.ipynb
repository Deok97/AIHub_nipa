{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Deok97/AIHub_nipa/blob/main/Korean_handwritten_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5991f33b-f9e4-4832-972d-bfd62c3dccd6",
      "metadata": {
        "id": "5991f33b-f9e4-4832-972d-bfd62c3dccd6"
      },
      "source": [
        "# 이미지/기초과제/손글씨 탐지\n",
        "\n",
        "이 노트북은 셀을 차례로 실행하여 이미지 과제의 전반적인 과정을 수행해볼 수 있게 제작되었습니다.\n",
        "\n",
        "## 과제 설명\n",
        "손글씨로 쓰여진 텍스트 이미지에서 텍스트를 탐지하는 과제\n",
        "\n",
        "## 데이터 설명\n",
        "- 학습 데이터 : 손글씨 이미지 데이터(.png)\n",
        "\n",
        "- 라벨 데이터 : 이미지의 크기, 파일명, 텍스트 등의 정보가 딕셔너리 형태로 담긴 데이터(.json)\n",
        "\n",
        "- 데이터셋 구성\n",
        "  - train: 5772개의 png 파일과 1개의 json 파일\n",
        "  - test: 1077개의 png 파일과 1개의 json 파일\n",
        "\n",
        "## 자주 사용되는 RNN 모델\n",
        "- LSTM, GRU 등\n",
        "\n",
        "## 코드 구조\n",
        "이 베이스라인 코드는 간단하게 아래 네 단계로 이루어져 있습니다.\n",
        "- `1.데이터`: 사용할 데이터셋을 가져오고 모델에 전달할 Dataloader 생성\n",
        "  - `class CustomDataset`: 데이터를 불러오고 (필요할 경우) 데이터 전처리 진행, 및 torch.utils.data.DataLoader의 첫번째 인자 형식으로 변환\n",
        "  - `torch.utils.data.DataLoader(dataset, batch_size=, ...)`: 모델에 공급할 데이터 로더 생성\n",
        "- `2.모델 설계`: 학습 및 추론에 사용할 모델 구조 설계\n",
        "  - `class CRNN`: 모델 구조 설계\n",
        "- `3.학습`: 설계된 모델로 데이터 학습\n",
        "  - 학습된 모델은 `.ipynb` 코드와 같은 경로에 저장됨\n",
        "- `4.추론`: 학습된 모델을 사용해 테스트 데이터로 추론\n",
        "  - 학습된 모델로 테스트 데이터에 대한 추론을 진행\n",
        "  - 추론 결과는 `.ipynb` 코드와 같은 경로에 저장됨. 이를 플랫폼에 업로드해 점수 확인"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1d47ea1-723a-4af4-ac75-ce38742fc8cf",
      "metadata": {
        "id": "f1d47ea1-723a-4af4-ac75-ce38742fc8cf"
      },
      "source": [
        "## 세팅\n",
        "### 라이브러리\n",
        "- 코드 전반에 사용되는 라이브러리를 설치 및 로드합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "970ba844-e326-44d9-af7a-4da97a593a9b",
      "metadata": {
        "id": "970ba844-e326-44d9-af7a-4da97a593a9b"
      },
      "outputs": [],
      "source": [
        "# 설치되지 않은 라이브러리의 경우, 주석 해제 후 코드를 실행하여 설치\n",
        "# !pip install torch\n",
        "# !pip install "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0605a52d-8322-40cb-81e0-61b8c78a2aaf",
      "metadata": {
        "id": "0605a52d-8322-40cb-81e0-61b8c78a2aaf"
      },
      "outputs": [],
      "source": [
        "# 필요한 라이브러리 불러오기\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import argparse\n",
        "import collections\n",
        "from PIL import Image\n",
        "from glob import glob\n",
        "import sklearn\n",
        "import sklearn.metrics\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import CTCLoss\n",
        "from torch.utils import data\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "W3ImJDrbeH3B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0ed7ed4-fd24-41b0-f21d-26947123702c"
      },
      "id": "W3ImJDrbeH3B",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6af95e2e-cdd1-44b2-8c5c-4c1cff23e653",
      "metadata": {
        "id": "6af95e2e-cdd1-44b2-8c5c-4c1cff23e653"
      },
      "outputs": [],
      "source": [
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\" # Use GPU 2\n",
        "\n",
        "# 경로 설정\n",
        "# DATASET_PATH = '/workspace/01_data/01_handwritten/02_processed' # origin data path\n",
        "DATASET_PATH = '/content/gdrive/MyDrive/sample/handwritten'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c934c14c-ab9b-46fa-9c87-921627f8ea23",
      "metadata": {
        "id": "c934c14c-ab9b-46fa-9c87-921627f8ea23"
      },
      "source": [
        "## 데이터\n",
        "### 전처리 방법\n",
        "\n",
        "해당 베이스라인에서는 이미지 과제에서 자주 사용되는 resize, normalize, bilinear interpolation 등을 적용합니다.\n",
        "- resize : 손글씨 각 이미지 파일의 크기가 다른 점을 보정하기 위해 지정된 규격으로 이미지 크기를 통일합니다.\n",
        "- normalize : 정규분포를 따르는 변수에서 평균을 빼고 표준편차로 나누면 표준정규분포를 따르게 되듯이, 마찬가지로 일정 값을 빼고 또한 나눠 정규화를 해줍니다.\n",
        "- bilinear interpolation : bilinear interpolation 방법은 이미지와 같은 height, width의 속성을 가지는 데이터에 적합한 interpolation 방법입니다.\n",
        "  -  height, width로 구성된 2차원 평면이므로 interpolation 할 때 사용되는 변수도 2개입니다.\n",
        "  - 이 방법은 단 방향의, 1개의 변수를 이용하여 interpolation 하는 linear 보다 좀 더 나은 방법입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62087e6d-7194-490c-b72c-97d88f2b1cb6",
      "metadata": {
        "id": "62087e6d-7194-490c-b72c-97d88f2b1cb6"
      },
      "source": [
        "### 데이터 로드 및 전처리\n",
        "- 데이터 로드 및 이미지 데이터 사이즈 변경, 표준화 등을 위한 클래스 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e743988-0526-42fe-b49d-6235a6936b7c",
      "metadata": {
        "id": "4e743988-0526-42fe-b49d-6235a6936b7c"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(data.Dataset): # data.Dataset 클래스 상속\n",
        "    \"\"\" 필수 함수 : \n",
        "        - __init__ : 초기화\n",
        "        - __len__ : 데이터셋(input)의 길이 반환\n",
        "        - __getitem__ : 데이터셋을 인덱스로 불러옴\n",
        "        \n",
        "        그 외 함수:\n",
        "        - get_root : 경로 반환\n",
        "        - get_img_path : 인덱스 출력\n",
        "    \"\"\"\n",
        " \n",
        "    def __init__(self, root, phase='train', transform=None, target_transform=None):\n",
        "        # 경로 생성 후 생성된 경로의 이미지 파일을 불러와 정렬한 다음 저장\n",
        "        self.root = os.path.join(root, 'd2', phase)\n",
        "        self.labels = []\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        annotations = None\n",
        "\n",
        "        if phase == 'val':\n",
        "            self.root = os.path.join(root,'d2','train')\n",
        "            \n",
        "        # 라벨 데이터인 json 파일을 불러와 저장한 다음 json 파일 안의 딕셔너리를 파일 이름 순으로 정렬\n",
        "        if phase != 'test':\n",
        "            with open(os.path.join(self.root, 'labels.json'), 'r') as label_json :\n",
        "                label_json = json.load(label_json)\n",
        "                annotations = label_json['annotations']\n",
        "            annotations = sorted(annotations, key=lambda x: x['file_name'])\n",
        "        \n",
        "        self.imgs = sorted(glob(self.root + '/images' + '/*.png'))\n",
        "        \n",
        "        \n",
        "        if phase == 'train':\n",
        "            annotations = annotations[:int(0.9*len(annotations))]\n",
        "            self.imgs = self.imgs[:int(0.9*len(self.imgs))]\n",
        "            for anno in annotations :\n",
        "                self.labels.append(anno['text'])\n",
        "        elif phase == 'val':\n",
        "            annotations = annotations[int(0.9*len(annotations)):]\n",
        "            self.imgs = self.imgs[int(0.9*len(self.imgs)):]\n",
        "            for anno in annotations :\n",
        "                self.labels.append(anno['text'])\n",
        "        elif phase == 'test':\n",
        "            self.labels = list(np.repeat(['dummy'], repeats=len(self.imgs), axis=None)) # len(self.imgs)개의 dummy\n",
        "            \n",
        "\n",
        "    # training set의 손글씨 이미지들의 갯수 출력\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "\n",
        "    # 데이터 셋의 idx 번째 샘플 데이터를 반환\n",
        "    def __getitem__(self, index):\n",
        "        assert index <= len(self), 'index range error'\n",
        "        img_path = self.imgs[index]\n",
        "        # 이미지 모드 변경. 흰 배경에 검은 글씨 뿐이므로 그레이 스케일('L') 지정\n",
        "        img = Image.open(img_path).convert('L')\n",
        "        \n",
        "        label = self.labels[index]\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        if self.target_transform is not None:\n",
        "            label = self.target_transform(label)\n",
        "\n",
        "        return (img, label)\n",
        "    \n",
        "    # CustomDataset 클래스의 __init__ 메서드에서 정의한 self.root 출력\n",
        "    def get_root(self) :\n",
        "        return self.root\n",
        "\n",
        "    # 해당 index의 이미지 파일의 경로 출력\n",
        "    def get_img_path(self, index) :\n",
        "        return self.imgs[index]\n",
        "    \n",
        "\n",
        "# 이미지 사이즈 변경(resize), 이중선형보간(bilinear interpolation), 텐서 변환, 표준화(normalize) \n",
        "# 선형보간법: 직선의 비율을 이용하여 두 점(x1와 x2) 사이의 점 x의 값을 추정하는 기법\n",
        "# 이중선형보간은 선형보간법을 2D에 적용하는 것\n",
        "class resizeNormalize(object):\n",
        "\n",
        "    def __init__(self, size, interpolation=Image.BILINEAR): # from PIL import Image\n",
        "        self.size = size\n",
        "        self.interpolation = interpolation\n",
        "        self.toTensor = transforms.ToTensor()\n",
        "\n",
        "    # __call__ function: 클래스 객체를 함수처럼 이용할 수 있게 함\n",
        "    def __call__(self, img): \n",
        "        img = img.resize(self.size, self.interpolation)\n",
        "        img = self.toTensor(img)\n",
        "        img.sub_(0.5).div_(0.5)\n",
        "        return img\n",
        "\n",
        "\n",
        "class alignCollate(object): \n",
        "\n",
        "    def __init__(self, imgH=32, imgW=100):\n",
        "        self.imgH = imgH\n",
        "        self.imgW = imgW\n",
        "\n",
        "    def __call__(self, batch):\n",
        "        images, labels = zip(*batch) # zip(*iterable)은 동일한 개수로 이루어진 자료형을 묶어 주는 역할을 하는 함수이다.\n",
        "       \n",
        "        imgH = self.imgH\n",
        "        imgW = self.imgW\n",
        "\n",
        "        transform = resizeNormalize((imgW, imgH)) # resizeNormalize __init__ 실행\n",
        "        images = [transform(image) for image in images] # transform은 resizeNormalize의 객체. __call__ 실행\n",
        "        images = torch.cat([t.unsqueeze(0) for t in images], 0)\n",
        "\n",
        "        return images, labels\n",
        "\n",
        "\n",
        "class strLabelConverter(object):\n",
        "  \n",
        "    def __init__(self, alphabet, ignore_case=True):\n",
        "        self._ignore_case = ignore_case        \n",
        "        if self._ignore_case:\n",
        "            alphabet = alphabet.lower()\n",
        "        self.alphabet = alphabet + '-'  # for `-1` index\n",
        "        \n",
        "        self.dict = {}\n",
        "        \n",
        "        # 식별의 대상이 되는 특수문자, 숫자, 알파벳 대소문자, 한글 각 기호/글자에 넘버링\n",
        "        for i, char in enumerate(alphabet):\n",
        "            # NOTE: 0 is reserved for 'blank' required by wrap_ctc\n",
        "            self.dict[char] = i + 1 \n",
        "            \n",
        "    def encode(self, text):\n",
        "        \"\"\"Support batch or single str.\n",
        "\n",
        "        Args:\n",
        "            text (str or list of str): texts to convert.\n",
        "\n",
        "        Returns:\n",
        "            torch.IntTensor [length_0 + length_1 + ... length_{n - 1}]: encoded texts.\n",
        "            torch.IntTensor [n]: length of each text.\n",
        "        \"\"\"\n",
        "        if isinstance(text, str): \n",
        "            # 필요 시 영어 문자를 모두 소문자 형식으로 반환\n",
        "            text = [\n",
        "                self.dict[char.lower() if self._ignore_case else char]\n",
        "                for char in text\n",
        "            ]\n",
        "            length = [len(text)]\n",
        "            \n",
        "        elif isinstance(text, collections.Iterable):\n",
        "            length = [len(s) for s in text]\n",
        "            text = ''.join(text)\n",
        "            text, _ = self.encode(text)\n",
        "        \n",
        "        return (torch.IntTensor(text), torch.IntTensor(length))\n",
        "\n",
        "    def decode(self, t, length, raw=False):\n",
        "        \"\"\"Decode encoded texts back into strs.\n",
        "\n",
        "        Args:\n",
        "            torch.IntTensor [length_0 + length_1 + ... length_{n - 1}]: encoded texts.\n",
        "            torch.IntTensor [n]: length of each text.\n",
        "\n",
        "        Raises:\n",
        "            AssertionError: when the texts and its length does not match.\n",
        "\n",
        "        Returns:\n",
        "            text (str or list of str): texts to convert.\n",
        "        \"\"\"\n",
        "        if length.numel() == 1:\n",
        "        # torch.numel(input) -> int : returns the total number of elements in the input tensor.\n",
        "            length = length[0]\n",
        "            assert t.numel() == length, \"text with length: {} does not match declared length: {}\".format(t.numel(), length)\n",
        "            if raw:\n",
        "                return ''.join([self.alphabet[i - 1] for i in t])\n",
        "            else:\n",
        "                char_list = []\n",
        "                for i in range(length):\n",
        "                    if t[i] != 0 and (not (i > 0 and t[i - 1] == t[i])):\n",
        "                        char_list.append(self.alphabet[t[i] - 1])\n",
        "                return ''.join(char_list)\n",
        "        else:\n",
        "            # batch mode\n",
        "            assert t.numel() == length.sum(), \"texts with length: {} does not match declared length: {}\".format(t.numel(), length.sum())\n",
        "            texts = []\n",
        "            index = 0\n",
        "            for i in range(length.numel()):\n",
        "                l = length[i]\n",
        "                texts.append(\n",
        "                    self.decode(\n",
        "                        t[index:index + l], torch.IntTensor([l]), raw=raw))\n",
        "                index += l\n",
        "            return texts\n",
        "        \n",
        "        \n",
        "def loadData(v, data):\n",
        "    d_size = data.size()\n",
        "    v.resize_(d_size).copy_(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2031e1eb-00f2-4be8-bd6b-c3d895897a44",
      "metadata": {
        "id": "2031e1eb-00f2-4be8-bd6b-c3d895897a44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cba06a9a-deac-4c1e-d42e-af9763e14cbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_dataset length: 5194, validation dataset length: 578\n"
          ]
        }
      ],
      "source": [
        "# DATASET 만들기\n",
        "train_dataset = CustomDataset(DATASET_PATH, phase='train')\n",
        "validation_dataset = CustomDataset(DATASET_PATH, phase='val')\n",
        "\n",
        "print(f'train_dataset length: {len(train_dataset)}, validation dataset length: {len(validation_dataset)}')\n",
        "\n",
        "# 데이터 로드 파라미터\n",
        "batch = 2\n",
        "imgH = 32\n",
        "imgW = 200\n",
        "\n",
        "# DATASET 로딩하기\n",
        "# collate_fn: batch_sampler로 묶인 이후에는, collate_fn을 호출해서 batch로 묶는다.\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch, shuffle=True, collate_fn=alignCollate(imgH=imgH, imgW=imgW))\n",
        "val_loader = DataLoader(validation_dataset, batch_size=batch, shuffle=False, collate_fn=alignCollate(imgH=imgH, imgW=imgW))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "992fe83c-d052-4c26-8958-6ce6a9a01936",
      "metadata": {
        "id": "992fe83c-d052-4c26-8958-6ce6a9a01936"
      },
      "source": [
        "## 모델 설계\n",
        "- 파이토치로 신경망을 구축할 때 사용되는 함수들은 torch.nn 패키지에 속해 있다.\n",
        "- torch.nn.Module 클래스의 상속 클래스를 생성하여 모델을 원하는 방식으로 구체적으로 설계한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54b39f20-3b0c-4d07-a545-68c5c56ddcde",
      "metadata": {
        "id": "54b39f20-3b0c-4d07-a545-68c5c56ddcde"
      },
      "outputs": [],
      "source": [
        "# torch.nn.Module 클래스 상속 후 모델에 필요한 연산 정의 및 모델 내 연산 순서 설정\n",
        "class BidirectionalLSTM(nn.Module): # torch.nn.Module 클래스 상속\n",
        "\n",
        "    def __init__(self, nIn, nHidden, nOut):\n",
        "        super(BidirectionalLSTM, self).__init__()\n",
        "        self.rnn = nn.LSTM(nIn, nHidden, bidirectional=True)\n",
        "        self.embedding = nn.Linear(nHidden * 2, nOut)\n",
        "\n",
        "    def forward(self, input):\n",
        "        recurrent, _ = self.rnn(input)\n",
        "        T, b, h = recurrent.size()\n",
        "        t_rec = recurrent.view(T * b, h)\n",
        "\n",
        "        output = self.embedding(t_rec)  # [T * b, nOut]\n",
        "        output = output.view(T, b, -1)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "class CRNN(nn.Module): # torch.nn.Module 클래스 상속\n",
        "\n",
        "    def __init__(self, imgH, nc, nclass, nh, n_rnn=2, leakyRelu=False):\n",
        "        super(CRNN, self).__init__()\n",
        "        assert imgH % 16 == 0, 'imgH has to be a multiple of 16'\n",
        "        \n",
        "        ks = [3, 3, 3, 3, 3, 3, 2]\n",
        "        ps = [1, 1, 1, 1, 1, 1, 0]\n",
        "        ss = [1, 1, 1, 1, 1, 1, 1]\n",
        "        nm = [64, 128, 256, 256, 512, 512, 512]\n",
        "\n",
        "        cnn = nn.Sequential()\n",
        "\n",
        "        def convRelu(i, batchNormalization=False):\n",
        "            nIn = nc if i == 0 else nm[i - 1]\n",
        "            nOut = nm[i]\n",
        "            cnn.add_module('conv{0}'.format(i),\n",
        "                           nn.Conv2d(nIn, nOut, ks[i], ss[i], ps[i]))\n",
        "            if batchNormalization:\n",
        "                cnn.add_module('batchnorm{0}'.format(i), nn.BatchNorm2d(nOut))\n",
        "            if leakyRelu:\n",
        "                cnn.add_module('relu{0}'.format(i),\n",
        "                               nn.LeakyReLU(0.2, inplace=True))\n",
        "            else:\n",
        "                cnn.add_module('relu{0}'.format(i), nn.ReLU(True))\n",
        "       \n",
        "        convRelu(0)\n",
        "        cnn.add_module('pooling{0}'.format(0), nn.MaxPool2d(2, 2))\n",
        "        convRelu(1)\n",
        "        cnn.add_module('pooling{0}'.format(1), nn.MaxPool2d(2, 2))\n",
        "        convRelu(2, True)\n",
        "        convRelu(3)\n",
        "        cnn.add_module('pooling{0}'.format(2),\n",
        "                       nn.MaxPool2d((2, 2), (2, 1), (0, 1))) \n",
        "        convRelu(4, True)\n",
        "        convRelu(5)\n",
        "        cnn.add_module('pooling{0}'.format(3),\n",
        "                       nn.MaxPool2d((2, 2), (2, 1), (0, 1)))\n",
        "        convRelu(6, True)\n",
        "\n",
        "        self.cnn = cnn\n",
        "        self.rnn = nn.Sequential(\n",
        "            BidirectionalLSTM(512, nh, nh),\n",
        "            BidirectionalLSTM(nh, nh, nclass))\n",
        "\n",
        "    def forward(self, input):\n",
        "        # conv features\n",
        "        conv = self.cnn(input)\n",
        "        b, c, h, w = conv.size()\n",
        "        assert h == 1, \"the height of conv must be 1\"\n",
        "        conv = conv.squeeze(2)\n",
        "        conv = conv.permute(2, 0, 1)  # [w, b, c]\n",
        "        # rnn features\n",
        "        output = self.rnn(conv)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a465ec5a-3ea8-4279-988a-7e8252d29529",
      "metadata": {
        "id": "a465ec5a-3ea8-4279-988a-7e8252d29529"
      },
      "source": [
        "## 학습\n",
        "### 사용할 파라미터\n",
        "- `optimizer` : 손실함수 값이 최소가 되는 부분을 찾기 위해 학습율과 기울기를 다양하게 수정하여 가중치를 변경시키는 것을 최적화라고 하고, 최적화의 다양한 방식들을 옵티마이저라고 합니다.\n",
        "- `epoch` : 한 번의 epoch는 인공 신경망에서 전체 데이터 셋에 대해 forward pass/backward pass 과정을 거친 것입니다.\n",
        "  - 즉, epoch이 1만큼 지나면, 전체 데이터 셋에 대해 한번의 학습이 완료된 상태입니다.\n",
        "  - 모델을 만들 때 적절한 epoch 값을 설정해야만 underfitting과 overfitting을 방지할 수 있습니다.\n",
        "  - 1 epoch = (데이터 갯수 / batch size) interations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe0f94ce-c9ca-4b4b-8231-f9360102043d",
      "metadata": {
        "id": "fe0f94ce-c9ca-4b4b-8231-f9360102043d"
      },
      "outputs": [],
      "source": [
        "model_dir = '/content/gdrive/MyDrive/sample/handwritten' \n",
        "\n",
        "def save_model(model_name, model, optimizer, scheduler):\n",
        "    os.makedirs(os.path.join(model_dir),exist_ok=True)\n",
        "    state = {\n",
        "        'model': model.state_dict(),\n",
        "        'optimizer': optimizer.state_dict(),\n",
        "        'scheduler': scheduler.state_dict()\n",
        "    }\n",
        "    torch.save(state, os.path.join(model_dir, model_name + '.pth'))\n",
        "    print('model saved')    \n",
        "\n",
        "    \n",
        "def load_model(model_name, model, optimizer=None, scheduler=None):\n",
        "    state = torch.load(os.path.join(model_dir, model_name + '.pth'))\n",
        "    model.load_state_dict(state['model'])\n",
        "    if optimizer is not None:\n",
        "        optimizer.load_state_dict(state['optimizer'])\n",
        "    if scheduler is not None:\n",
        "        scheduler.load_state_dict(state['scheduler'])\n",
        "    print('model loaded')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e4a5ab1-40be-419f-9d0a-4834cfc6be2c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e4a5ab1-40be-419f-9d0a-4834cfc6be2c",
        "outputId": "a99533a5-f6a1-4438-d69a-b7752b674b9f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'file_name': '00000003.png',\n",
              "  'height': 175,\n",
              "  'text': '정권자였는데 이에 대한 사과가 우선\"이라고 했다. 한편 문 후보와 김',\n",
              "  'width': 3739},\n",
              " {'file_name': '00000004.png',\n",
              "  'height': 177,\n",
              "  'text': '위원장과의 악연도 화제였다. 두 사람의 악연은 지난 2003년 철도노',\n",
              "  'width': 3716},\n",
              " {'file_name': '00000006.png',\n",
              "  'height': 177,\n",
              "  'text': '노조 파업에 공권력 투입을 사실상 결정했고, 김 위원장은 철도노조',\n",
              "  'width': 3650},\n",
              " {'file_name': '00000008.png',\n",
              "  'height': 176,\n",
              "  'text': '서 \"2003년 파업 때 공권력 투입을 계기로 참여정부의 노동정책이',\n",
              "  'width': 3613},\n",
              " {'file_name': '00000009.png',\n",
              "  'height': 176,\n",
              "  'text': '꼬이기 시작했다\"며 \"문 후보도 그 부분에 대한 아쉬움을 얘기했고 최',\n",
              "  'width': 3756}]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "# load json file\n",
        "with open(os.path.join('/content/gdrive/MyDrive/sample/handwritten/d2/train/labels.json'), 'r') as label_json :\n",
        "    handwritten_json = json.load(label_json)\n",
        "    \n",
        "sorted(handwritten_json['annotations'], key=lambda x: x['file_name'])[0]['text']\n",
        "handwritten_json['annotations'][:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### evaluation을 위해 필요한 함수 정의"
      ],
      "metadata": {
        "id": "h2r_ni1WmndQ"
      },
      "id": "h2r_ni1WmndQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92cf5d4f-54b0-4beb-b3dd-83a84d99f393",
      "metadata": {
        "id": "92cf5d4f-54b0-4beb-b3dd-83a84d99f393"
      },
      "outputs": [],
      "source": [
        "def editDistance(r, h):\n",
        "\n",
        "    d = np.zeros((len(r)+1)*(len(h)+1), dtype=np.uint8).reshape((len(r)+1, len(h)+1))\n",
        "    for i in range(len(r)+1):\n",
        "        d[i][0] = i\n",
        "    for j in range(len(h)+1):\n",
        "        d[0][j] = j\n",
        "    for i in range(1, len(r)+1):\n",
        "        for j in range(1, len(h)+1):\n",
        "            if r[i-1] == h[j-1]:\n",
        "                d[i][j] = d[i-1][j-1]\n",
        "            else:\n",
        "                substitute = d[i-1][j-1] + 1\n",
        "                insert = d[i][j-1] + 1\n",
        "                delete = d[i-1][j] + 1\n",
        "                d[i][j] = min(substitute, insert, delete)\n",
        "    return d\n",
        "\n",
        "# wer(wor error rate) 참조 링크\n",
        "# https://docs.microsoft.com/ko-kr/azure/cognitive-services/speech-service/how-to-custom-speech-evaluate-data\n",
        "def wer(r, h):\n",
        "\n",
        "    # build the matrix\n",
        "    d = editDistance(r, h)\n",
        "\n",
        "    # print the result in aligned way\n",
        "    result = float(d[len(r)][len(h)]) / len(r) * 100\n",
        "    return result\n",
        "\n",
        "def evaluation_metrics(pred_list):\n",
        "    return evaluate(pred_list)\n",
        "\n",
        "\n",
        "def evaluate(pred_list):\n",
        "    \n",
        "\n",
        "    total_wer = 0\n",
        "    \n",
        "    for i in range(len(pred_list)) :\n",
        "        wer_val = wer(validation_dataset.labels[i].split(), pred_list[i].split())\n",
        "        total_wer += wer_val\n",
        "    ret = total_wer / len(pred_list)\n",
        "    return ret"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### train/test/val function"
      ],
      "metadata": {
        "id": "FSCAFDZ1mpid"
      },
      "id": "FSCAFDZ1mpid"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48bf2de4-2ba0-40c1-a056-d41a7999336c",
      "metadata": {
        "id": "48bf2de4-2ba0-40c1-a056-d41a7999336c"
      },
      "outputs": [],
      "source": [
        "def train(num_epochs, model, device, train_loader, val_loader, images, texts, lengths, converter, optimizer, lr_scheduler, prediction_dir, print_iter) :\n",
        "    criterion = CTCLoss()\n",
        "    criterion.to(device)\n",
        "    images = images.to(device)\n",
        "    model.to(device)\n",
        "    for epoch in range(num_epochs) : # 0 ~ num_epochs-1\n",
        "        print(f'epoch: {epoch}')\n",
        "        count = 0\n",
        "        model.train()\n",
        "        for i, datas in enumerate(train_loader) :\n",
        "            datas, targets = datas\n",
        "            batch_size = datas.size(0)\n",
        "            count += batch_size\n",
        "            loadData(images, datas)\n",
        "            t, l = converter.encode(targets)\n",
        "            loadData(texts, t)\n",
        "            loadData(lengths, l)\n",
        "            \n",
        "            # 모델 학습 진행\n",
        "            preds = model(images)\n",
        "            preds_size = Variable(torch.IntTensor([preds.size(0)] * batch_size))\n",
        "            # loss 계산->back-propagation\n",
        "            cost = criterion(preds, texts, preds_size, lengths) / batch_size\n",
        "            model.zero_grad()\n",
        "            cost.backward()\n",
        "            optimizer.step()\n",
        "            if count % print_iter < train_loader.batch_size :\n",
        "                print('epoch {} [{}/{}]loss : {}'.format(epoch, count, len(train_loader.dataset), cost))\n",
        "\n",
        "        # 검증\n",
        "        validation(model, device, val_loader, images, texts, lengths, converter, prediction_dir)\n",
        "       \n",
        "        save_model('{}'.format(epoch), model, optimizer, lr_scheduler)\n",
        "        \n",
        "        lr_scheduler.step()\n",
        "\n",
        "def validation(model, device, val_loader, images, texts, lengths, converter, prediction_dir):\n",
        "    image_path_list, pred_list = test(model, device, val_loader, images, texts, lengths, converter, prediction_dir)\n",
        "    print('validation test finish')\n",
        "\n",
        "    # 추론 점수 계산\n",
        "    res = evaluation_metrics(pred_list)\n",
        "\n",
        "    print('validation : ', res)\n",
        "    \n",
        "    \n",
        "def test(model, device, test_loader, images, texts, lengths, converter, prediction_dir) :\n",
        "    model.to(device)\n",
        "    images = images.to(device)\n",
        "    model.eval()\n",
        "    image_path_list = test_loader.dataset.imgs\n",
        "    pred_list = []\n",
        "    os.makedirs(os.path.join(prediction_dir), exist_ok=True)\n",
        "    for i, datas in enumerate(test_loader) :\n",
        "        datas, targets = datas\n",
        "        batch_size = datas.size(0)\n",
        "        loadData(images, datas)\n",
        "        t, l = converter.encode(targets)\n",
        "        loadData(texts, t)\n",
        "        loadData(lengths, l)\n",
        "\n",
        "        # 추론\n",
        "        preds = model(images)\n",
        "        \n",
        "        preds_size = Variable(torch.IntTensor([preds.size(0)] * batch_size))\n",
        "        \n",
        "        _, preds = preds.max(2)\n",
        "        preds = preds.transpose(1, 0).contiguous().view(-1)\n",
        "        # 추론 결과 decode\n",
        "        pred_string = converter.decode(preds.data, preds_size.data, raw=False)\n",
        "        \n",
        "        # 추론 결과 list로 저장\n",
        "        if type(pred_string) is str:\n",
        "            pred_list.append(pred_string)\n",
        "        else:\n",
        "            pred_list.extend(pred_string)\n",
        "        \n",
        "    return image_path_list, pred_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94dd34d1-eb4b-4210-b373-d4c03b4f9630",
      "metadata": {
        "id": "94dd34d1-eb4b-4210-b373-d4c03b4f9630"
      },
      "outputs": [],
      "source": [
        "# 파라미터 지정   \n",
        "letter = \" ,.()\\'\\\"?!01234567890abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ가각간갇갈갉갊감갑값갓갔강갖갗같갚갛개객갠갤갬갭갯갰갱갸갹갼걀걋걍걔걘걜거걱건걷걸걺검겁것겄겅겆겉겊겋게겐겔겜겝겟겠겡겨격겪견겯결겸겹겻겼경곁계곈곌곕곗고곡곤곧골곪곬곯곰곱곳공곶과곽관괄괆괌괍괏광괘괜괠괩괬괭괴괵괸괼굄굅굇굉교굔굘굡굣구국군굳굴굵굶굻굼굽굿궁궂궈궉권궐궜궝궤궷귀귁귄귈귐귑귓규균귤그극근귿글긁금급긋긍긔기긱긴긷길긺김깁깃깅깆깊까깍깎깐깔깖깜깝깟깠깡깥깨깩깬깰깸깹깻깼깽꺄꺅꺌꺼꺽꺾껀껄껌껍껏껐껑께껙껜껨껫껭껴껸껼꼇꼈꼍꼐꼬꼭꼰꼲꼴꼼꼽꼿꽁꽂꽃꽈꽉꽐꽜꽝꽤꽥꽹꾀꾄꾈꾐꾑꾕꾜꾸꾹꾼꿀꿇꿈꿉꿋꿍꿎꿔꿜꿨꿩꿰꿱꿴꿸뀀뀁뀄뀌뀐뀔뀜뀝뀨끄끅끈끊끌끎끓끔끕끗끙끝끼끽낀낄낌낍낏낑나낙낚난낟날낡낢남납낫났낭낮낯낱낳내낵낸낼냄냅냇냈냉냐냑냔냘냠냥너넉넋넌널넒넓넘넙넛넜넝넣네넥넨넬넴넵넷넸넹녀녁년녈념녑녔녕녘녜녠노녹논놀놂놈놉놋농높놓놔놘놜놨뇌뇐뇔뇜뇝뇟뇨뇩뇬뇰뇹뇻뇽누눅눈눋눌눔눕눗눙눠눴눼뉘뉜뉠뉨뉩뉴뉵뉼늄늅늉느늑는늘늙늚늠늡늣능늦늪늬늰늴니닉닌닐닒님닙닛닝닢다닥닦단닫달닭닮닯닳담답닷닸당닺닻닿대댁댄댈댐댑댓댔댕댜더덕덖던덛덜덞덟덤덥덧덩덫덮데덱덴델뎀뎁뎃뎄뎅뎌뎐뎔뎠뎡뎨뎬도독돈돋돌돎돐돔돕돗동돛돝돠돤돨돼됐되된될됨됩됫됴두둑둔둘둠둡둣둥둬뒀뒈뒝뒤뒨뒬뒵뒷뒹듀듄듈듐듕드득든듣들듦듬듭듯등듸디딕딘딛딜딤딥딧딨딩딪따딱딴딸땀땁땃땄땅땋때땍땐땔땜땝땟땠땡떠떡떤떨떪떫떰떱떳떴떵떻떼떽뗀뗄뗌뗍뗏뗐뗑뗘뗬또똑똔똘똥똬똴뙈뙤뙨뚜뚝뚠뚤뚫뚬뚱뛔뛰뛴뛸뜀뜁뜅뜨뜩뜬뜯뜰뜸뜹뜻띄띈띌띔띕띠띤띨띰띱띳띵라락란랄람랍랏랐랑랒랖랗래랙랜랠램랩랫랬랭랴략랸럇량러럭런럴럼럽럿렀렁렇레렉렌렐렘렙렛렝려력련렬렴렵렷렸령례롄롑롓로록론롤롬롭롯롱롸롼뢍뢨뢰뢴뢸룀룁룃룅료룐룔룝룟룡루룩룬룰룸룹룻룽뤄뤘뤠뤼뤽륀륄륌륏륑류륙륜률륨륩륫륭르륵른를름릅릇릉릊릍릎리릭린릴림립릿링마막만많맏말맑맒맘맙맛망맞맡맣매맥맨맬맴맵맷맸맹맺먀먁먈먕머먹먼멀멂멈멉멋멍멎멓메멕멘멜멤멥멧멨멩며멱면멸몃몄명몇몌모목몫몬몰몲몸몹못몽뫄뫈뫘뫙뫼묀묄묍묏묑묘묜묠묩묫무묵묶문묻물묽묾뭄뭅뭇뭉뭍뭏뭐뭔뭘뭡뭣뭬뮈뮌뮐뮤뮨뮬뮴뮷므믄믈믐믓미믹민믿밀밂밈밉밋밌밍및밑바박밖밗반받발밝밞밟밤밥밧방밭배백밴밸뱀뱁뱃뱄뱅뱉뱌뱍뱐뱝버벅번벋벌벎범법벗벙벚베벡벤벧벨벰벱벳벴벵벼벽변별볍볏볐병볕볘볜보복볶본볼봄봅봇봉봐봔봤봬뵀뵈뵉뵌뵐뵘뵙뵤뵨부북분붇불붉붊붐붑붓붕붙붚붜붤붰붸뷔뷕뷘뷜뷩뷰뷴뷸븀븃븅브븍븐블븜븝븟비빅빈빌빎빔빕빗빙빚빛빠빡빤빨빪빰빱빳빴빵빻빼빽뺀뺄뺌뺍뺏뺐뺑뺘뺙뺨뻐뻑뻔뻗뻘뻠뻣뻤뻥뻬뼁뼈뼉뼘뼙뼛뼜뼝뽀뽁뽄뽈뽐뽑뽕뾔뾰뿅뿌뿍뿐뿔뿜뿟뿡쀼쁑쁘쁜쁠쁨쁩삐삑삔삘삠삡삣삥사삭삯산삳살삵삶삼삽삿샀상샅새색샌샐샘샙샛샜생샤샥샨샬샴샵샷샹섀섄섈섐섕서석섞섟선섣설섦섧섬섭섯섰성섶세섹센셀셈셉셋셌셍셔셕션셜셤셥셧셨셩셰셴셸솅소속솎손솔솖솜솝솟송솥솨솩솬솰솽쇄쇈쇌쇔쇗쇘쇠쇤쇨쇰쇱쇳쇼쇽숀숄숌숍숏숑수숙순숟술숨숩숫숭숯숱숲숴쉈쉐쉑쉔쉘쉠쉥쉬쉭쉰쉴쉼쉽쉿슁슈슉슐슘슛슝스슥슨슬슭슴습슷승시식신싣실싫심십싯싱싶싸싹싻싼쌀쌈쌉쌌쌍쌓쌔쌕쌘쌜쌤쌥쌨쌩썅써썩썬썰썲썸썹썼썽쎄쎈쎌쏀쏘쏙쏜쏟쏠쏢쏨쏩쏭쏴쏵쏸쐈쐐쐤쐬쐰쐴쐼쐽쑈쑤쑥쑨쑬쑴쑵쑹쒀쒔쒜쒸쒼쓩쓰쓱쓴쓸쓺쓿씀씁씌씐씔씜씨씩씬씰씸씹씻씽아악안앉않알앍앎앓암압앗았앙앝앞애액앤앨앰앱앳앴앵야약얀얄얇얌얍얏양얕얗얘얜얠얩어억언얹얻얼얽얾엄업없엇었엉엊엌엎에엑엔엘엠엡엣엥여역엮연열엶엷염엽엾엿였영옅옆옇예옌옐옘옙옛옜오옥온올옭옮옰옳옴옵옷옹옻와왁완왈왐왑왓왔왕왜왝왠왬왯왱외왹왼욀욈욉욋욍요욕욘욜욤욥욧용우욱운울욹욺움웁웃웅워웍원월웜웝웠웡웨웩웬웰웸웹웽위윅윈윌윔윕윗윙유육윤율윰윱윳융윷으윽은을읊음읍읏응읒읓읔읕읖읗의읩읜읠읨읫이익인일읽읾잃임입잇있잉잊잎자작잔잖잗잘잚잠잡잣잤장잦재잭잰잴잼잽잿쟀쟁쟈쟉쟌쟎쟐쟘쟝쟤쟨쟬저적전절젊점접젓정젖제젝젠젤젬젭젯젱져젼졀졈졉졌졍졔조족존졸졺좀좁좃종좆좇좋좌좍좔좝좟좡좨좼좽죄죈죌죔죕죗죙죠죡죤죵주죽준줄줅줆줌줍줏중줘줬줴쥐쥑쥔쥘쥠쥡쥣쥬쥰쥴쥼즈즉즌즐즘즙즛증지직진짇질짊짐집짓징짖짙짚짜짝짠짢짤짧짬짭짯짰짱째짹짼쨀쨈쨉쨋쨌쨍쨔쨘쨩쩌쩍쩐쩔쩜쩝쩟쩠쩡쩨쩽쪄쪘쪼쪽쫀쫄쫌쫍쫏쫑쫓쫘쫙쫠쫬쫴쬈쬐쬔쬘쬠쬡쭁쭈쭉쭌쭐쭘쭙쭝쭤쭸쭹쮜쮸쯔쯤쯧쯩찌찍찐찔찜찝찡찢찧차착찬찮찰참찹찻찼창찾채책챈챌챔챕챗챘챙챠챤챦챨챰챵처척천철첨첩첫첬청체첵첸첼쳄쳅쳇쳉쳐쳔쳤쳬쳰촁초촉촌촐촘촙촛총촤촨촬촹최쵠쵤쵬쵭쵯쵱쵸춈추축춘출춤춥춧충춰췄췌췐취췬췰췸췹췻췽츄츈츌츔츙츠측츤츨츰츱츳층치칙친칟칠칡침칩칫칭카칵칸칼캄캅캇캉캐캑캔캘캠캡캣캤캥캬캭컁커컥컨컫컬컴컵컷컸컹케켁켄켈켐켑켓켕켜켠켤켬켭켯켰켱켸코콕콘콜콤콥콧콩콰콱콴콸쾀쾅쾌쾡쾨쾰쿄쿠쿡쿤쿨쿰쿱쿳쿵쿼퀀퀄퀑퀘퀭퀴퀵퀸퀼큄큅큇큉큐큔큘큠크큭큰클큼큽킁키킥킨킬킴킵킷킹타탁탄탈탉탐탑탓탔탕태택탠탤탬탭탯탰탱탸턍터턱턴털턺텀텁텃텄텅테텍텐텔템텝텟텡텨텬텼톄톈토톡톤톨톰톱톳통톺톼퇀퇘퇴퇸툇툉툐투툭툰툴툼툽툿퉁퉈퉜퉤튀튁튄튈튐튑튕튜튠튤튬튱트특튼튿틀틂틈틉틋틔틘틜틤틥티틱틴틸팀팁팃팅파팍팎판팔팖팜팝팟팠팡팥패팩팬팰팸팹팻팼팽퍄퍅퍼퍽펀펄펌펍펏펐펑페펙펜펠펨펩펫펭펴편펼폄폅폈평폐폘폡폣포폭폰폴폼폽폿퐁퐈퐝푀푄표푠푤푭푯푸푹푼푿풀풂품풉풋풍풔풩퓌퓐퓔퓜퓟퓨퓬퓰퓸퓻퓽프픈플픔픕픗피픽핀필핌핍핏핑하학한할핥함합핫항해핵핸핼햄햅햇했행햐향허헉헌헐헒험헙헛헝헤헥헨헬헴헵헷헹혀혁현혈혐협혓혔형혜혠혤혭호혹혼홀홅홈홉홋홍홑화확환활홧황홰홱홴횃횅회획횐횔횝횟횡효횬횰횹횻후훅훈훌훑훔훗훙훠훤훨훰훵훼훽휀휄휑휘휙휜휠휨휩휫휭휴휵휸휼흄흇흉흐흑흔흖흗흘흙흠흡흣흥흩희흰흴흼흽힁히힉힌힐힘힙힛힝\"\n",
        "lr = 0.0001\n",
        "cuda = True\n",
        "num_epochs = 50 # model_name = '99'\n",
        "model_name = '49'\n",
        "mode = \"train\"\n",
        "prediction_dir = '/content/gdrive/MyDrive/sample/handwritten/prediction'\n",
        "print_iter = 500\n",
        "nclass = len(letter) + 1\n",
        "nc = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34e3d8ee-89a6-4a8c-baa6-9f52f4c26a8b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34e3d8ee-89a6-4a8c-baa6-9f52f4c26a8b",
        "outputId": "9e6b85f6-caa3-43b9-c4cd-47e87d8a0066"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------\n",
            "num of parameter :  9555832\n",
            "num of trainable_ parameter : 9555832\n",
            "------------------------------------------------------------\n",
            "CRNN(\n",
            "  (cnn): Sequential(\n",
            "    (conv0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (relu0): ReLU(inplace=True)\n",
            "    (pooling0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (relu1): ReLU(inplace=True)\n",
            "    (pooling1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (batchnorm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu2): ReLU(inplace=True)\n",
            "    (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (relu3): ReLU(inplace=True)\n",
            "    (pooling2): MaxPool2d(kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n",
            "    (conv4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (batchnorm4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu4): ReLU(inplace=True)\n",
            "    (conv5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (relu5): ReLU(inplace=True)\n",
            "    (pooling3): MaxPool2d(kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n",
            "    (conv6): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1))\n",
            "    (batchnorm6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu6): ReLU(inplace=True)\n",
            "  )\n",
            "  (rnn): Sequential(\n",
            "    (0): BidirectionalLSTM(\n",
            "      (rnn): LSTM(512, 256, bidirectional=True)\n",
            "      (embedding): Linear(in_features=512, out_features=256, bias=True)\n",
            "    )\n",
            "    (1): BidirectionalLSTM(\n",
            "      (rnn): LSTM(256, 256, bidirectional=True)\n",
            "      (embedding): Linear(in_features=512, out_features=2424, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# custom weights initialization called on crnn\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        m.weight.data.normal_(0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(1.0, 0.02)\n",
        "        m.bias.data.fill_(0)\n",
        "\n",
        "# 모델 선언\n",
        "new_model = CRNN(imgH, nc, nclass, 256)\n",
        "new_model.apply(weights_init)\n",
        "\n",
        "converter = strLabelConverter(letter)\n",
        "    \n",
        "images = torch.FloatTensor(batch, 1, imgH, imgW)\n",
        "texts = torch.IntTensor(batch * 1000)\n",
        "lengths = torch.IntTensor(batch)\n",
        "    \n",
        "images = Variable(images)\n",
        "texts = Variable(texts)\n",
        "lengths = Variable(lengths)\n",
        "\n",
        "#check parameter of model\n",
        "print(\"------------------------------------------------------------\")\n",
        "total_params = sum(p.numel() for p in new_model.parameters())\n",
        "print(\"num of parameter : \",total_params)\n",
        "trainable_params = sum(p.numel() for p in new_model.parameters() if p.requires_grad)\n",
        "print(\"num of trainable_ parameter :\",trainable_params)\n",
        "print(\"------------------------------------------------------------\")\n",
        "\n",
        "# check model architecture\n",
        "print(new_model)\n",
        "print(\"------------------------------------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5feb4d0e-83c9-40ed-a03c-1c3c3081d9a6",
      "metadata": {
        "id": "5feb4d0e-83c9-40ed-a03c-1c3c3081d9a6"
      },
      "source": [
        "## 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94c2fdfb-8a4f-4fa5-ba95-32aff7217006",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "94c2fdfb-8a4f-4fa5-ba95-32aff7217006",
        "outputId": "b21c66d1-9ec6-4bae-c2f3-758dc6e2d945"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train start\n",
            "epoch: 0\n",
            "epoch 0 [500/5194]loss : 2.473896026611328\n",
            "epoch 0 [1000/5194]loss : 2.4514260292053223\n",
            "epoch 0 [1500/5194]loss : 2.4506287574768066\n",
            "epoch 0 [2000/5194]loss : 2.6230547428131104\n",
            "epoch 0 [2500/5194]loss : 2.3616294860839844\n",
            "epoch 0 [3000/5194]loss : 2.4844160079956055\n",
            "epoch 0 [3500/5194]loss : 2.4868264198303223\n",
            "epoch 0 [4000/5194]loss : 2.5057427883148193\n",
            "epoch 0 [4500/5194]loss : 2.5389723777770996\n",
            "epoch 0 [5000/5194]loss : 2.3837854862213135\n",
            "validation test finish\n",
            "validation :  100.0\n",
            "model saved\n",
            "epoch: 1\n",
            "epoch 1 [500/5194]loss : 2.425530195236206\n",
            "epoch 1 [1000/5194]loss : 2.2314887046813965\n",
            "epoch 1 [1500/5194]loss : 2.503909111022949\n",
            "epoch 1 [2000/5194]loss : 2.2566208839416504\n",
            "epoch 1 [2500/5194]loss : 2.097740650177002\n",
            "epoch 1 [3000/5194]loss : 2.075450897216797\n",
            "epoch 1 [3500/5194]loss : 2.2624826431274414\n",
            "epoch 1 [4000/5194]loss : 2.1829583644866943\n",
            "epoch 1 [4500/5194]loss : 2.157896041870117\n",
            "epoch 1 [5000/5194]loss : 2.0994105339050293\n",
            "validation test finish\n",
            "validation :  100.29542209040477\n",
            "model saved\n",
            "epoch: 2\n",
            "epoch 2 [500/5194]loss : 2.020246982574463\n",
            "epoch 2 [1000/5194]loss : 2.10640549659729\n",
            "epoch 2 [1500/5194]loss : 2.0978341102600098\n",
            "epoch 2 [2000/5194]loss : 2.0063834190368652\n",
            "epoch 2 [2500/5194]loss : 1.9130241870880127\n",
            "epoch 2 [3000/5194]loss : 2.2746763229370117\n",
            "epoch 2 [3500/5194]loss : 2.0946459770202637\n",
            "epoch 2 [4000/5194]loss : 2.2301101684570312\n",
            "epoch 2 [4500/5194]loss : 2.032515048980713\n",
            "epoch 2 [5000/5194]loss : 1.7386647462844849\n",
            "validation test finish\n",
            "validation :  100.0\n",
            "model saved\n",
            "epoch: 3\n",
            "epoch 3 [500/5194]loss : 1.8375396728515625\n",
            "epoch 3 [1000/5194]loss : 1.8509496450424194\n",
            "epoch 3 [1500/5194]loss : 1.753922462463379\n",
            "epoch 3 [2000/5194]loss : 2.030003070831299\n",
            "epoch 3 [2500/5194]loss : 2.7472848892211914\n",
            "epoch 3 [3000/5194]loss : 1.7546920776367188\n",
            "epoch 3 [3500/5194]loss : 1.5957610607147217\n",
            "epoch 3 [4000/5194]loss : 2.013387441635132\n",
            "epoch 3 [4500/5194]loss : 1.7928614616394043\n",
            "epoch 3 [5000/5194]loss : 1.8558430671691895\n",
            "validation test finish\n",
            "validation :  100.97615427632729\n",
            "model saved\n",
            "epoch: 4\n",
            "epoch 4 [500/5194]loss : 1.4209659099578857\n",
            "epoch 4 [1000/5194]loss : 1.853553295135498\n",
            "epoch 4 [1500/5194]loss : 1.5490121841430664\n",
            "epoch 4 [2000/5194]loss : 1.5487396717071533\n",
            "epoch 4 [2500/5194]loss : 1.8413283824920654\n",
            "epoch 4 [3000/5194]loss : 1.439622163772583\n",
            "epoch 4 [3500/5194]loss : 1.5372469425201416\n",
            "epoch 4 [4000/5194]loss : 1.644606590270996\n",
            "epoch 4 [4500/5194]loss : 1.4837384223937988\n",
            "epoch 4 [5000/5194]loss : 1.4886022806167603\n",
            "validation test finish\n",
            "validation :  99.39751569076829\n",
            "model saved\n",
            "epoch: 5\n",
            "epoch 5 [500/5194]loss : 1.6654636859893799\n",
            "epoch 5 [1000/5194]loss : 1.7033133506774902\n",
            "epoch 5 [1500/5194]loss : 1.4851701259613037\n",
            "epoch 5 [2000/5194]loss : 1.3309032917022705\n",
            "epoch 5 [2500/5194]loss : 1.3065129518508911\n",
            "epoch 5 [3000/5194]loss : 1.4363435506820679\n",
            "epoch 5 [3500/5194]loss : 1.385376214981079\n",
            "epoch 5 [4000/5194]loss : 1.6672217845916748\n",
            "epoch 5 [4500/5194]loss : 1.5080931186676025\n",
            "epoch 5 [5000/5194]loss : 1.2871360778808594\n",
            "validation test finish\n",
            "validation :  100.39867283811923\n",
            "model saved\n",
            "epoch: 6\n",
            "epoch 6 [500/5194]loss : 1.3165818452835083\n",
            "epoch 6 [1000/5194]loss : 1.295934796333313\n",
            "epoch 6 [1500/5194]loss : 1.6895815134048462\n",
            "epoch 6 [2000/5194]loss : 1.3854913711547852\n",
            "epoch 6 [2500/5194]loss : 1.4416595697402954\n",
            "epoch 6 [3000/5194]loss : 1.5460071563720703\n",
            "epoch 6 [3500/5194]loss : 1.1877007484436035\n",
            "epoch 6 [4000/5194]loss : 1.0712099075317383\n",
            "epoch 6 [4500/5194]loss : 1.3312158584594727\n",
            "epoch 6 [5000/5194]loss : 1.0728943347930908\n",
            "validation test finish\n",
            "validation :  98.48851840201324\n",
            "model saved\n",
            "epoch: 7\n",
            "epoch 7 [500/5194]loss : 1.2594764232635498\n",
            "epoch 7 [1000/5194]loss : 1.151448369026184\n",
            "epoch 7 [1500/5194]loss : 1.3929705619812012\n",
            "epoch 7 [2000/5194]loss : 1.0320823192596436\n",
            "epoch 7 [2500/5194]loss : 1.2030137777328491\n",
            "epoch 7 [3000/5194]loss : 1.4823107719421387\n",
            "epoch 7 [3500/5194]loss : 1.124678134918213\n",
            "epoch 7 [4000/5194]loss : 1.1680253744125366\n",
            "epoch 7 [4500/5194]loss : 1.1163408756256104\n",
            "epoch 7 [5000/5194]loss : 1.3168795108795166\n",
            "validation test finish\n",
            "validation :  98.27653075490446\n",
            "model saved\n",
            "epoch: 8\n",
            "epoch 8 [500/5194]loss : 1.5839664936065674\n",
            "epoch 8 [1000/5194]loss : 0.8202874660491943\n",
            "epoch 8 [1500/5194]loss : 1.0025924444198608\n",
            "epoch 8 [2000/5194]loss : 1.2403335571289062\n",
            "epoch 8 [2500/5194]loss : 0.8354001641273499\n",
            "epoch 8 [3000/5194]loss : 1.1882847547531128\n",
            "epoch 8 [3500/5194]loss : 1.110365629196167\n",
            "epoch 8 [4000/5194]loss : 0.9484224319458008\n",
            "epoch 8 [4500/5194]loss : 0.9651721715927124\n",
            "epoch 8 [5000/5194]loss : 1.4281259775161743\n",
            "validation test finish\n",
            "validation :  96.6042343853763\n",
            "model saved\n",
            "epoch: 9\n",
            "epoch 9 [500/5194]loss : 0.6465210914611816\n",
            "epoch 9 [1000/5194]loss : 0.6164501905441284\n",
            "epoch 9 [1500/5194]loss : 0.9953259229660034\n",
            "epoch 9 [2000/5194]loss : 0.9206969738006592\n",
            "epoch 9 [2500/5194]loss : 0.7536910772323608\n",
            "epoch 9 [3000/5194]loss : 0.7936436533927917\n",
            "epoch 9 [3500/5194]loss : 0.8036308288574219\n",
            "epoch 9 [4000/5194]loss : 0.7104872465133667\n",
            "epoch 9 [4500/5194]loss : 1.205397605895996\n",
            "epoch 9 [5000/5194]loss : 0.6899188756942749\n",
            "validation test finish\n",
            "validation :  98.14128057640167\n",
            "model saved\n",
            "epoch: 10\n",
            "epoch 10 [500/5194]loss : 0.6934038400650024\n",
            "epoch 10 [1000/5194]loss : 0.9427409172058105\n",
            "epoch 10 [1500/5194]loss : 0.7911295890808105\n",
            "epoch 10 [2000/5194]loss : 0.8646637201309204\n",
            "epoch 10 [2500/5194]loss : 0.6681065559387207\n",
            "epoch 10 [3000/5194]loss : 0.6731650233268738\n",
            "epoch 10 [3500/5194]loss : 0.8543338775634766\n",
            "epoch 10 [4000/5194]loss : 0.757681131362915\n",
            "epoch 10 [4500/5194]loss : 0.45462071895599365\n",
            "epoch 10 [5000/5194]loss : 0.8748447895050049\n",
            "validation test finish\n",
            "validation :  95.32475646229977\n",
            "model saved\n",
            "epoch: 11\n",
            "epoch 11 [500/5194]loss : 0.8834922313690186\n",
            "epoch 11 [1000/5194]loss : 0.9804642796516418\n",
            "epoch 11 [1500/5194]loss : 0.8734762668609619\n",
            "epoch 11 [2000/5194]loss : 0.562791109085083\n",
            "epoch 11 [2500/5194]loss : 0.9584357738494873\n",
            "epoch 11 [3000/5194]loss : 0.686670184135437\n",
            "epoch 11 [3500/5194]loss : 0.7023811340332031\n",
            "epoch 11 [4000/5194]loss : 0.5566612482070923\n",
            "epoch 11 [4500/5194]loss : 0.616513192653656\n",
            "epoch 11 [5000/5194]loss : 1.0290244817733765\n",
            "validation test finish\n",
            "validation :  95.68859629413268\n",
            "model saved\n",
            "epoch: 12\n",
            "epoch 12 [500/5194]loss : 0.6908825039863586\n",
            "epoch 12 [1000/5194]loss : 0.7113108038902283\n",
            "epoch 12 [1500/5194]loss : 0.5265142917633057\n",
            "epoch 12 [2000/5194]loss : 0.46602511405944824\n",
            "epoch 12 [2500/5194]loss : 0.38298702239990234\n",
            "epoch 12 [3000/5194]loss : 0.7880102396011353\n",
            "epoch 12 [3500/5194]loss : 0.9437842965126038\n",
            "epoch 12 [4000/5194]loss : 0.6857202053070068\n",
            "epoch 12 [4500/5194]loss : 0.563309371471405\n",
            "epoch 12 [5000/5194]loss : 0.4885714054107666\n",
            "validation test finish\n",
            "validation :  95.20993664159764\n",
            "model saved\n",
            "epoch: 13\n",
            "epoch 13 [500/5194]loss : 0.4750300347805023\n",
            "epoch 13 [1000/5194]loss : 0.4807744324207306\n",
            "epoch 13 [1500/5194]loss : 0.4521147608757019\n",
            "epoch 13 [2000/5194]loss : 0.5868359804153442\n",
            "epoch 13 [2500/5194]loss : 0.43311673402786255\n",
            "epoch 13 [3000/5194]loss : 0.5084726810455322\n",
            "epoch 13 [3500/5194]loss : 0.4533615708351135\n",
            "epoch 13 [4000/5194]loss : 2.0466668605804443\n",
            "epoch 13 [4500/5194]loss : 0.5726346373558044\n",
            "epoch 13 [5000/5194]loss : 0.5900036096572876\n",
            "validation test finish\n",
            "validation :  94.4598668344344\n",
            "model saved\n",
            "epoch: 14\n",
            "epoch 14 [500/5194]loss : 0.31272003054618835\n",
            "epoch 14 [1000/5194]loss : 0.5105378031730652\n",
            "epoch 14 [1500/5194]loss : 0.37307319045066833\n",
            "epoch 14 [2000/5194]loss : 0.9239586591720581\n",
            "epoch 14 [2500/5194]loss : 0.5453310012817383\n",
            "epoch 14 [3000/5194]loss : 0.2470322549343109\n",
            "epoch 14 [3500/5194]loss : 0.48615115880966187\n",
            "epoch 14 [4000/5194]loss : 0.3820072412490845\n",
            "epoch 14 [4500/5194]loss : 0.2746179401874542\n",
            "epoch 14 [5000/5194]loss : 0.5859292149543762\n",
            "validation test finish\n",
            "validation :  93.26927829955527\n",
            "model saved\n",
            "epoch: 15\n",
            "epoch 15 [500/5194]loss : 0.5323878526687622\n",
            "epoch 15 [1000/5194]loss : 0.36938947439193726\n",
            "epoch 15 [1500/5194]loss : 0.22078295052051544\n",
            "epoch 15 [2000/5194]loss : 0.48820334672927856\n",
            "epoch 15 [2500/5194]loss : 0.319553405046463\n",
            "epoch 15 [3000/5194]loss : 0.2732264995574951\n",
            "epoch 15 [3500/5194]loss : 0.3109414577484131\n",
            "epoch 15 [4000/5194]loss : 0.4289860129356384\n",
            "epoch 15 [4500/5194]loss : 0.2895890474319458\n",
            "epoch 15 [5000/5194]loss : 0.5195517539978027\n",
            "validation test finish\n",
            "validation :  90.04901576700897\n",
            "model saved\n",
            "epoch: 16\n",
            "epoch 16 [500/5194]loss : 0.41515669226646423\n",
            "epoch 16 [1000/5194]loss : 0.2471330463886261\n",
            "epoch 16 [1500/5194]loss : 0.2292279601097107\n",
            "epoch 16 [2000/5194]loss : 0.28190481662750244\n",
            "epoch 16 [2500/5194]loss : 0.42318448424339294\n",
            "epoch 16 [3000/5194]loss : 0.21327954530715942\n",
            "epoch 16 [3500/5194]loss : 0.3822857737541199\n",
            "epoch 16 [4000/5194]loss : 0.3019155263900757\n",
            "epoch 16 [4500/5194]loss : 0.3062019944190979\n",
            "epoch 16 [5000/5194]loss : 0.26354631781578064\n",
            "validation test finish\n",
            "validation :  90.38218365640526\n",
            "model saved\n",
            "epoch: 17\n",
            "epoch 17 [500/5194]loss : 0.28883570432662964\n",
            "epoch 17 [1000/5194]loss : 0.22034958004951477\n",
            "epoch 17 [1500/5194]loss : 0.30872899293899536\n",
            "epoch 17 [2000/5194]loss : 0.10982761532068253\n",
            "epoch 17 [2500/5194]loss : 0.1995702087879181\n",
            "epoch 17 [3000/5194]loss : 0.16395244002342224\n",
            "epoch 17 [3500/5194]loss : 0.2336074560880661\n",
            "epoch 17 [4000/5194]loss : 0.428683876991272\n",
            "epoch 17 [4500/5194]loss : 0.17021673917770386\n",
            "epoch 17 [5000/5194]loss : 0.2598719000816345\n",
            "validation test finish\n",
            "validation :  90.11983835080733\n",
            "model saved\n",
            "epoch: 18\n",
            "epoch 18 [500/5194]loss : 0.18483760952949524\n",
            "epoch 18 [1000/5194]loss : 0.15047675371170044\n",
            "epoch 18 [1500/5194]loss : 0.11286690831184387\n",
            "epoch 18 [2000/5194]loss : 0.15964728593826294\n",
            "epoch 18 [2500/5194]loss : 0.14279070496559143\n",
            "epoch 18 [3000/5194]loss : 0.12058967351913452\n",
            "epoch 18 [3500/5194]loss : 0.2032485008239746\n",
            "epoch 18 [4000/5194]loss : 0.2467978298664093\n",
            "epoch 18 [4500/5194]loss : 0.1973947435617447\n",
            "epoch 18 [5000/5194]loss : 0.25848695635795593\n",
            "validation test finish\n",
            "validation :  89.68242973865827\n",
            "model saved\n",
            "epoch: 19\n",
            "epoch 19 [500/5194]loss : 0.1098351776599884\n",
            "epoch 19 [1000/5194]loss : 0.20781317353248596\n",
            "epoch 19 [1500/5194]loss : 0.36841505765914917\n",
            "epoch 19 [2000/5194]loss : 0.14477069675922394\n",
            "epoch 19 [2500/5194]loss : 0.18553924560546875\n",
            "epoch 19 [3000/5194]loss : 0.11529204994440079\n",
            "epoch 19 [3500/5194]loss : 0.19218701124191284\n",
            "epoch 19 [4000/5194]loss : 0.1488102376461029\n",
            "epoch 19 [4500/5194]loss : 0.14825955033302307\n",
            "epoch 19 [5000/5194]loss : 0.17419253289699554\n",
            "validation test finish\n",
            "validation :  92.58476817300355\n",
            "model saved\n",
            "epoch: 20\n",
            "epoch 20 [500/5194]loss : 0.19496819376945496\n",
            "epoch 20 [1000/5194]loss : 0.12133410573005676\n",
            "epoch 20 [1500/5194]loss : 0.13519258797168732\n",
            "epoch 20 [2000/5194]loss : 0.055651985108852386\n",
            "epoch 20 [2500/5194]loss : 0.10839924216270447\n",
            "epoch 20 [3000/5194]loss : 0.03602912649512291\n",
            "epoch 20 [3500/5194]loss : 0.11557337641716003\n",
            "epoch 20 [4000/5194]loss : 0.08945368230342865\n",
            "epoch 20 [4500/5194]loss : 0.09399834275245667\n",
            "epoch 20 [5000/5194]loss : 0.1666259467601776\n",
            "validation test finish\n",
            "validation :  89.00801812566537\n",
            "model saved\n",
            "epoch: 21\n",
            "epoch 21 [500/5194]loss : 0.04163442552089691\n",
            "epoch 21 [1000/5194]loss : 0.18714459240436554\n",
            "epoch 21 [1500/5194]loss : 0.09932208061218262\n",
            "epoch 21 [2000/5194]loss : 0.09097780287265778\n",
            "epoch 21 [2500/5194]loss : 0.15216472744941711\n",
            "epoch 21 [3000/5194]loss : 0.13114559650421143\n",
            "epoch 21 [3500/5194]loss : 0.128371462225914\n",
            "epoch 21 [4000/5194]loss : 0.09432616829872131\n",
            "epoch 21 [4500/5194]loss : 0.09090223908424377\n",
            "epoch 21 [5000/5194]loss : 0.1510208547115326\n",
            "validation test finish\n",
            "validation :  88.76127236853895\n",
            "model saved\n",
            "epoch: 22\n",
            "epoch 22 [500/5194]loss : 0.029925469309091568\n",
            "epoch 22 [1000/5194]loss : 0.0469132736325264\n",
            "epoch 22 [1500/5194]loss : 0.08572991192340851\n",
            "epoch 22 [2000/5194]loss : 0.056243766099214554\n",
            "epoch 22 [2500/5194]loss : 0.045826807618141174\n",
            "epoch 22 [3000/5194]loss : 0.15518388152122498\n",
            "epoch 22 [3500/5194]loss : 0.033495672047138214\n",
            "epoch 22 [4000/5194]loss : 0.1384936273097992\n",
            "epoch 22 [4500/5194]loss : 0.08969028294086456\n",
            "epoch 22 [5000/5194]loss : 0.11019331216812134\n",
            "validation test finish\n",
            "validation :  88.76861604370268\n",
            "model saved\n",
            "epoch: 23\n",
            "epoch 23 [500/5194]loss : 0.025719724595546722\n",
            "epoch 23 [1000/5194]loss : 0.021151874214410782\n",
            "epoch 23 [1500/5194]loss : 0.03868168964982033\n",
            "epoch 23 [2000/5194]loss : 0.06535239517688751\n",
            "epoch 23 [2500/5194]loss : 0.049643903970718384\n",
            "epoch 23 [3000/5194]loss : 0.08572159707546234\n",
            "epoch 23 [3500/5194]loss : 0.04109860211610794\n",
            "epoch 23 [4000/5194]loss : 0.11017487198114395\n",
            "epoch 23 [4500/5194]loss : 0.06663402169942856\n",
            "epoch 23 [5000/5194]loss : 0.041562534868717194\n",
            "validation test finish\n",
            "validation :  88.20288899873688\n",
            "model saved\n",
            "epoch: 24\n",
            "epoch 24 [500/5194]loss : 0.06755371391773224\n",
            "epoch 24 [1000/5194]loss : 0.03794243186712265\n",
            "epoch 24 [1500/5194]loss : 0.1482599973678589\n",
            "epoch 24 [2000/5194]loss : 0.026114244014024734\n",
            "epoch 24 [2500/5194]loss : 0.04465430602431297\n",
            "epoch 24 [3000/5194]loss : 0.07790357619524002\n",
            "epoch 24 [3500/5194]loss : 0.037931762635707855\n",
            "epoch 24 [4000/5194]loss : 0.03423748165369034\n",
            "epoch 24 [4500/5194]loss : 0.09336555004119873\n",
            "epoch 24 [5000/5194]loss : 0.07553882151842117\n",
            "validation test finish\n",
            "validation :  88.05479651067894\n",
            "model saved\n",
            "epoch: 25\n",
            "epoch 25 [500/5194]loss : 0.029684526845812798\n",
            "epoch 25 [1000/5194]loss : 0.0794266015291214\n",
            "epoch 25 [1500/5194]loss : 0.029931392520666122\n",
            "epoch 25 [2000/5194]loss : 0.05971979349851608\n",
            "epoch 25 [2500/5194]loss : 0.04159333556890488\n",
            "epoch 25 [3000/5194]loss : 0.022991441190242767\n",
            "epoch 25 [3500/5194]loss : 0.045575227588415146\n",
            "epoch 25 [4000/5194]loss : 0.03443584591150284\n",
            "epoch 25 [4500/5194]loss : 0.03187565132975578\n",
            "epoch 25 [5000/5194]loss : 0.0489460714161396\n",
            "validation test finish\n",
            "validation :  85.47205533797238\n",
            "model saved\n",
            "epoch: 26\n",
            "epoch 26 [500/5194]loss : 0.03327658027410507\n",
            "epoch 26 [1000/5194]loss : 0.014669522643089294\n",
            "epoch 26 [1500/5194]loss : 0.018525507301092148\n",
            "epoch 26 [2000/5194]loss : 0.03748476877808571\n",
            "epoch 26 [2500/5194]loss : 0.16458335518836975\n",
            "epoch 26 [3000/5194]loss : 0.04884283244609833\n",
            "epoch 26 [3500/5194]loss : 0.04165675491094589\n",
            "epoch 26 [4000/5194]loss : 0.03635592758655548\n",
            "epoch 26 [4500/5194]loss : 0.018587030470371246\n",
            "epoch 26 [5000/5194]loss : 0.045769102871418\n",
            "validation test finish\n",
            "validation :  87.52491597214787\n",
            "model saved\n",
            "epoch: 27\n",
            "epoch 27 [500/5194]loss : 0.032581500709056854\n",
            "epoch 27 [1000/5194]loss : 0.008565090596675873\n",
            "epoch 27 [1500/5194]loss : 0.017724722623825073\n",
            "epoch 27 [2000/5194]loss : 0.023646436631679535\n",
            "epoch 27 [2500/5194]loss : 0.017150182276964188\n",
            "epoch 27 [3000/5194]loss : 0.02550458535552025\n",
            "epoch 27 [3500/5194]loss : 0.03000805154442787\n",
            "epoch 27 [4000/5194]loss : 0.017782822251319885\n",
            "epoch 27 [4500/5194]loss : 0.06286191195249557\n",
            "epoch 27 [5000/5194]loss : 0.03158235922455788\n",
            "validation test finish\n",
            "validation :  86.8528429471337\n",
            "model saved\n",
            "epoch: 28\n",
            "epoch 28 [500/5194]loss : 0.026202823966741562\n",
            "epoch 28 [1000/5194]loss : 0.018642377108335495\n",
            "epoch 28 [1500/5194]loss : 0.019996974617242813\n",
            "epoch 28 [2000/5194]loss : 0.011389252729713917\n",
            "epoch 28 [2500/5194]loss : 0.02085835672914982\n",
            "epoch 28 [3000/5194]loss : 0.024973586201667786\n",
            "epoch 28 [3500/5194]loss : 0.05463990941643715\n",
            "epoch 28 [4000/5194]loss : 0.01932859793305397\n",
            "epoch 28 [4500/5194]loss : 0.057607680559158325\n",
            "epoch 28 [5000/5194]loss : 0.05415499955415726\n",
            "validation test finish\n",
            "validation :  87.30766062080941\n",
            "model saved\n",
            "epoch: 29\n",
            "epoch 29 [500/5194]loss : 0.029855819419026375\n",
            "epoch 29 [1000/5194]loss : 0.02425408363342285\n",
            "epoch 29 [1500/5194]loss : 0.015592057257890701\n",
            "epoch 29 [2000/5194]loss : 0.04156085476279259\n",
            "epoch 29 [2500/5194]loss : 0.01689925044775009\n",
            "epoch 29 [3000/5194]loss : 0.018681470304727554\n",
            "epoch 29 [3500/5194]loss : 0.04416605830192566\n",
            "epoch 29 [4000/5194]loss : 0.052804961800575256\n",
            "epoch 29 [4500/5194]loss : 0.03701218217611313\n",
            "epoch 29 [5000/5194]loss : 0.014809440821409225\n",
            "validation test finish\n",
            "validation :  87.18519465924322\n",
            "model saved\n",
            "epoch: 30\n",
            "epoch 30 [500/5194]loss : 0.009239415638148785\n",
            "epoch 30 [1000/5194]loss : 0.023722738027572632\n",
            "epoch 30 [1500/5194]loss : 0.12517686188220978\n",
            "epoch 30 [2000/5194]loss : 0.019485119730234146\n",
            "epoch 30 [2500/5194]loss : 0.0103928716853261\n",
            "epoch 30 [3000/5194]loss : 0.033012762665748596\n",
            "epoch 30 [3500/5194]loss : 0.022735880687832832\n",
            "epoch 30 [4000/5194]loss : 0.020141897723078728\n",
            "epoch 30 [4500/5194]loss : 0.3466176986694336\n",
            "epoch 30 [5000/5194]loss : 0.010544782504439354\n",
            "validation test finish\n",
            "validation :  85.81395440391995\n",
            "model saved\n",
            "epoch: 31\n",
            "epoch 31 [500/5194]loss : 0.024222223088145256\n",
            "epoch 31 [1000/5194]loss : 0.009094016626477242\n",
            "epoch 31 [1500/5194]loss : 0.029325969517230988\n",
            "epoch 31 [2000/5194]loss : 0.02141687646508217\n",
            "epoch 31 [2500/5194]loss : 0.018872657790780067\n",
            "epoch 31 [3000/5194]loss : 0.043858885765075684\n",
            "epoch 31 [3500/5194]loss : 0.02223837375640869\n",
            "epoch 31 [4000/5194]loss : 0.015411470085382462\n",
            "epoch 31 [4500/5194]loss : 0.05184851586818695\n",
            "epoch 31 [5000/5194]loss : 0.03935718536376953\n",
            "validation test finish\n",
            "validation :  87.32814234976881\n",
            "model saved\n",
            "epoch: 32\n",
            "epoch 32 [500/5194]loss : 0.020922068506479263\n",
            "epoch 32 [1000/5194]loss : 0.030603080987930298\n",
            "epoch 32 [1500/5194]loss : 0.02035491168498993\n",
            "epoch 32 [2000/5194]loss : 0.015067275613546371\n",
            "epoch 32 [2500/5194]loss : 0.03358098492026329\n",
            "epoch 32 [3000/5194]loss : 0.018119094893336296\n",
            "epoch 32 [3500/5194]loss : 0.21068944036960602\n",
            "epoch 32 [4000/5194]loss : 0.020629674196243286\n",
            "epoch 32 [4500/5194]loss : 0.009210813790559769\n",
            "epoch 32 [5000/5194]loss : 0.01628471538424492\n",
            "validation test finish\n",
            "validation :  86.11250533395874\n",
            "model saved\n",
            "epoch: 33\n",
            "epoch 33 [500/5194]loss : 0.030217880383133888\n",
            "epoch 33 [1000/5194]loss : 0.04319584369659424\n",
            "epoch 33 [1500/5194]loss : 0.021927714347839355\n",
            "epoch 33 [2000/5194]loss : 0.018827687948942184\n",
            "epoch 33 [2500/5194]loss : 0.028514910489320755\n",
            "epoch 33 [3000/5194]loss : 0.05971769988536835\n",
            "epoch 33 [3500/5194]loss : 0.031081313267350197\n",
            "epoch 33 [4000/5194]loss : 0.04707162454724312\n",
            "epoch 33 [4500/5194]loss : 0.05213406682014465\n",
            "epoch 33 [5000/5194]loss : 0.016706163063645363\n",
            "validation test finish\n",
            "validation :  90.64639848809405\n",
            "model saved\n",
            "epoch: 34\n",
            "epoch 34 [500/5194]loss : 0.03332905471324921\n",
            "epoch 34 [1000/5194]loss : 0.02057841047644615\n",
            "epoch 34 [1500/5194]loss : 0.031874243170022964\n",
            "epoch 34 [2000/5194]loss : 0.04931022599339485\n",
            "epoch 34 [2500/5194]loss : 0.007606443949043751\n",
            "epoch 34 [3000/5194]loss : 0.010240488685667515\n",
            "epoch 34 [3500/5194]loss : 0.01868255063891411\n",
            "epoch 34 [4000/5194]loss : 0.01217070035636425\n",
            "epoch 34 [4500/5194]loss : 0.05734935775399208\n",
            "epoch 34 [5000/5194]loss : 0.02961704321205616\n",
            "validation test finish\n",
            "validation :  83.70444290427004\n",
            "model saved\n",
            "epoch: 35\n",
            "epoch 35 [500/5194]loss : 0.02391144447028637\n",
            "epoch 35 [1000/5194]loss : 0.010284666903316975\n",
            "epoch 35 [1500/5194]loss : 0.07350822538137436\n",
            "epoch 35 [2000/5194]loss : 0.008206704631447792\n",
            "epoch 35 [2500/5194]loss : 0.016302336007356644\n",
            "epoch 35 [3000/5194]loss : 0.01003496628254652\n",
            "epoch 35 [3500/5194]loss : 0.022015728056430817\n",
            "epoch 35 [4000/5194]loss : 0.02018815279006958\n",
            "epoch 35 [4500/5194]loss : 0.01591368205845356\n",
            "epoch 35 [5000/5194]loss : 0.010051814839243889\n",
            "validation test finish\n",
            "validation :  86.38605627359959\n",
            "model saved\n",
            "epoch: 36\n",
            "epoch 36 [500/5194]loss : 0.007299042772501707\n",
            "epoch 36 [1000/5194]loss : 0.021845033392310143\n",
            "epoch 36 [1500/5194]loss : 0.01009423565119505\n",
            "epoch 36 [2000/5194]loss : 0.005472810938954353\n",
            "epoch 36 [2500/5194]loss : 0.016839098185300827\n",
            "epoch 36 [3000/5194]loss : 0.015876615419983864\n",
            "epoch 36 [3500/5194]loss : 0.1323886662721634\n",
            "epoch 36 [4000/5194]loss : 0.029564660042524338\n",
            "epoch 36 [4500/5194]loss : 0.010400060564279556\n",
            "epoch 36 [5000/5194]loss : 0.005139311775565147\n",
            "validation test finish\n",
            "validation :  84.0830579455148\n",
            "model saved\n",
            "epoch: 37\n",
            "epoch 37 [500/5194]loss : 0.020966025069355965\n",
            "epoch 37 [1000/5194]loss : 0.02702261134982109\n",
            "epoch 37 [1500/5194]loss : 0.010070428252220154\n",
            "epoch 37 [2000/5194]loss : 0.024959631264209747\n",
            "epoch 37 [2500/5194]loss : 0.01206926628947258\n",
            "epoch 37 [3000/5194]loss : 0.02494959533214569\n",
            "epoch 37 [3500/5194]loss : 0.00962682906538248\n",
            "epoch 37 [4000/5194]loss : 0.010397892445325851\n",
            "epoch 37 [4500/5194]loss : 0.0060926638543605804\n",
            "epoch 37 [5000/5194]loss : 0.010710607282817364\n",
            "validation test finish\n",
            "validation :  83.1418490198768\n",
            "model saved\n",
            "epoch: 38\n",
            "epoch 38 [500/5194]loss : 0.005162188317626715\n",
            "epoch 38 [1000/5194]loss : 0.0029210939537733793\n",
            "epoch 38 [1500/5194]loss : 0.006701399572193623\n",
            "epoch 38 [2000/5194]loss : 0.00563126802444458\n",
            "epoch 38 [2500/5194]loss : 0.02933266945183277\n",
            "epoch 38 [3000/5194]loss : 0.017269929870963097\n",
            "epoch 38 [3500/5194]loss : 0.023904550820589066\n",
            "epoch 38 [4000/5194]loss : 0.016850799322128296\n",
            "epoch 38 [4500/5194]loss : 0.08638914674520493\n",
            "epoch 38 [5000/5194]loss : 0.026756970211863518\n",
            "validation test finish\n",
            "validation :  85.75841882070266\n",
            "model saved\n",
            "epoch: 39\n",
            "epoch 39 [500/5194]loss : 0.014608836732804775\n",
            "epoch 39 [1000/5194]loss : 0.011822148226201534\n",
            "epoch 39 [1500/5194]loss : 0.0111757917329669\n",
            "epoch 39 [2000/5194]loss : 0.035670820623636246\n",
            "epoch 39 [2500/5194]loss : 0.01348427776247263\n",
            "epoch 39 [3000/5194]loss : 0.01030157320201397\n",
            "epoch 39 [3500/5194]loss : 0.014237670227885246\n",
            "epoch 39 [4000/5194]loss : 0.0035041719675064087\n",
            "epoch 39 [4500/5194]loss : 0.03394264727830887\n",
            "epoch 39 [5000/5194]loss : 0.04508350044488907\n",
            "validation test finish\n",
            "validation :  85.20941476823842\n",
            "model saved\n",
            "epoch: 40\n",
            "epoch 40 [500/5194]loss : 0.006644801236689091\n",
            "epoch 40 [1000/5194]loss : 0.009108366444706917\n",
            "epoch 40 [1500/5194]loss : 0.005984121933579445\n",
            "epoch 40 [2000/5194]loss : 0.0031805564649403095\n",
            "epoch 40 [2500/5194]loss : 0.007070049177855253\n",
            "epoch 40 [3000/5194]loss : 0.0032325144857168198\n",
            "epoch 40 [3500/5194]loss : 0.00504497392103076\n",
            "epoch 40 [4000/5194]loss : 0.01711644046008587\n",
            "epoch 40 [4500/5194]loss : 0.004117688164114952\n",
            "epoch 40 [5000/5194]loss : 0.007143163587898016\n",
            "validation test finish\n",
            "validation :  82.37652149849386\n",
            "model saved\n",
            "epoch: 41\n",
            "epoch 41 [500/5194]loss : 0.00397852249443531\n",
            "epoch 41 [1000/5194]loss : 0.003892442211508751\n",
            "epoch 41 [1500/5194]loss : 0.0038361898623406887\n",
            "epoch 41 [2000/5194]loss : 0.0036175595596432686\n",
            "epoch 41 [2500/5194]loss : 0.0012114958371967077\n",
            "epoch 41 [3000/5194]loss : 0.0027839108370244503\n",
            "epoch 41 [3500/5194]loss : 0.0031061870977282524\n",
            "epoch 41 [4000/5194]loss : 0.0023009427823126316\n",
            "epoch 41 [4500/5194]loss : 0.0020812195725739002\n",
            "epoch 41 [5000/5194]loss : 0.003565566847100854\n",
            "validation test finish\n",
            "validation :  82.34183204338925\n",
            "model saved\n",
            "epoch: 42\n",
            "epoch 42 [500/5194]loss : 0.0037648524157702923\n",
            "epoch 42 [1000/5194]loss : 0.004107045941054821\n",
            "epoch 42 [1500/5194]loss : 0.0029445323161780834\n",
            "epoch 42 [2000/5194]loss : 0.002715721260756254\n",
            "epoch 42 [2500/5194]loss : 0.002619018778204918\n",
            "epoch 42 [3000/5194]loss : 0.0019322906155139208\n",
            "epoch 42 [3500/5194]loss : 0.0030101530719548464\n",
            "epoch 42 [4000/5194]loss : 0.0012856406392529607\n",
            "epoch 42 [4500/5194]loss : 0.0018463949672877789\n",
            "epoch 42 [5000/5194]loss : 0.0037213535979390144\n",
            "validation test finish\n",
            "validation :  81.9369802631049\n",
            "model saved\n",
            "epoch: 43\n",
            "epoch 43 [500/5194]loss : 0.0019937807228416204\n",
            "epoch 43 [1000/5194]loss : 0.0026240653824061155\n",
            "epoch 43 [1500/5194]loss : 0.0012361728586256504\n",
            "epoch 43 [2000/5194]loss : 0.0013029859401285648\n",
            "epoch 43 [2500/5194]loss : 1.0331329107284546\n",
            "epoch 43 [3000/5194]loss : 0.0017939184326678514\n",
            "epoch 43 [3500/5194]loss : 0.0012066381750628352\n",
            "epoch 43 [4000/5194]loss : 0.0017038278747349977\n",
            "epoch 43 [4500/5194]loss : 0.0011449384037405252\n",
            "epoch 43 [5000/5194]loss : 0.0013188763987272978\n",
            "validation test finish\n",
            "validation :  81.77972738526383\n",
            "model saved\n",
            "epoch: 44\n",
            "epoch 44 [500/5194]loss : 0.0025270802434533834\n",
            "epoch 44 [1000/5194]loss : 0.0014182155719026923\n",
            "epoch 44 [1500/5194]loss : 0.0008419569348916411\n",
            "epoch 44 [2000/5194]loss : 0.0011217421852052212\n",
            "epoch 44 [2500/5194]loss : 0.0010965783149003983\n",
            "epoch 44 [3000/5194]loss : 0.0010544437682256103\n",
            "epoch 44 [3500/5194]loss : 0.0022008076775819063\n",
            "epoch 44 [4000/5194]loss : 0.001007881248369813\n",
            "epoch 44 [4500/5194]loss : 0.0012450594222173095\n",
            "epoch 44 [5000/5194]loss : 0.002941033337265253\n",
            "validation test finish\n",
            "validation :  81.15491342567478\n",
            "model saved\n",
            "epoch: 45\n",
            "epoch 45 [500/5194]loss : 0.0013987820129841566\n",
            "epoch 45 [1000/5194]loss : 0.0007618459640070796\n",
            "epoch 45 [1500/5194]loss : 0.0009543802589178085\n",
            "epoch 45 [2000/5194]loss : 0.0008748651016503572\n",
            "epoch 45 [2500/5194]loss : 0.0005461145774461329\n",
            "epoch 45 [3000/5194]loss : 0.0012525079073384404\n",
            "epoch 45 [3500/5194]loss : 0.0010739625431597233\n",
            "epoch 45 [4000/5194]loss : 0.001338068163022399\n",
            "epoch 45 [4500/5194]loss : 0.0011722384952008724\n",
            "epoch 45 [5000/5194]loss : 0.0014286627992987633\n",
            "validation test finish\n",
            "validation :  81.54559732846938\n",
            "model saved\n",
            "epoch: 46\n",
            "epoch 46 [500/5194]loss : 0.001288118539378047\n",
            "epoch 46 [1000/5194]loss : 0.0008555407403036952\n",
            "epoch 46 [1500/5194]loss : 0.001822562189772725\n",
            "epoch 46 [2000/5194]loss : 0.0014315105509012938\n",
            "epoch 46 [2500/5194]loss : 0.0024406537413597107\n",
            "epoch 46 [3000/5194]loss : 0.0011042794212698936\n",
            "epoch 46 [3500/5194]loss : 0.0014549432089552283\n",
            "epoch 46 [4000/5194]loss : 0.0007665861048735678\n",
            "epoch 46 [4500/5194]loss : 0.0018183270003646612\n",
            "epoch 46 [5000/5194]loss : 0.0016729934141039848\n",
            "validation test finish\n",
            "validation :  81.36137747296928\n",
            "model saved\n",
            "epoch: 47\n",
            "epoch 47 [500/5194]loss : 0.0011377728078514338\n",
            "epoch 47 [1000/5194]loss : 0.0010316085536032915\n",
            "epoch 47 [1500/5194]loss : 0.0007352660759352148\n",
            "epoch 47 [2000/5194]loss : 0.0010904759401455522\n",
            "epoch 47 [2500/5194]loss : 0.000801773858256638\n",
            "epoch 47 [3000/5194]loss : 0.001083211856894195\n",
            "epoch 47 [3500/5194]loss : 0.0005789224524050951\n",
            "epoch 47 [4000/5194]loss : 0.000504045863635838\n",
            "epoch 47 [4500/5194]loss : 0.0009896017145365477\n",
            "epoch 47 [5000/5194]loss : 0.00044483644887804985\n",
            "validation test finish\n",
            "validation :  80.94387878557437\n",
            "model saved\n",
            "epoch: 48\n",
            "epoch 48 [500/5194]loss : 0.0009497555438429117\n",
            "epoch 48 [1000/5194]loss : 0.0005399452056735754\n",
            "epoch 48 [1500/5194]loss : 0.0007915651658549905\n",
            "epoch 48 [2000/5194]loss : 0.0007963541429489851\n",
            "epoch 48 [2500/5194]loss : 0.0007461517816409469\n",
            "epoch 48 [3000/5194]loss : 0.0008496221271343529\n",
            "epoch 48 [3500/5194]loss : 0.0009729496669024229\n",
            "epoch 48 [4000/5194]loss : 0.0005205258494243026\n",
            "epoch 48 [4500/5194]loss : 0.0011611318914219737\n",
            "epoch 48 [5000/5194]loss : 0.0007965622935444117\n",
            "validation test finish\n",
            "validation :  81.78400895528938\n",
            "model saved\n",
            "epoch: 49\n",
            "epoch 49 [500/5194]loss : 0.0006017260020598769\n",
            "epoch 49 [1000/5194]loss : 0.0011752764694392681\n",
            "epoch 49 [1500/5194]loss : 0.0010848810197785497\n",
            "epoch 49 [2000/5194]loss : 0.0012207396794110537\n",
            "epoch 49 [2500/5194]loss : 0.0003651359584182501\n",
            "epoch 49 [3000/5194]loss : 0.0009082377655431628\n",
            "epoch 49 [3500/5194]loss : 0.0008643787587061524\n",
            "epoch 49 [4000/5194]loss : 0.0010488908737897873\n",
            "epoch 49 [4500/5194]loss : 0.0005957989487797022\n",
            "epoch 49 [5000/5194]loss : 0.0013824119232594967\n",
            "validation test finish\n",
            "validation :  81.83123297310159\n",
            "model saved\n",
            "epoch: 50\n",
            "epoch 50 [500/5194]loss : 0.0006637293845415115\n",
            "epoch 50 [1000/5194]loss : 0.0005492839263752103\n",
            "epoch 50 [1500/5194]loss : 0.0005135340616106987\n",
            "epoch 50 [2000/5194]loss : 0.0004474627203308046\n",
            "epoch 50 [2500/5194]loss : 0.0005694146966561675\n",
            "epoch 50 [3000/5194]loss : 0.0006601928034797311\n",
            "epoch 50 [3500/5194]loss : 0.0009328670566901565\n",
            "epoch 50 [4000/5194]loss : 0.0006489831721410155\n",
            "epoch 50 [4500/5194]loss : 0.0005546608008444309\n",
            "epoch 50 [5000/5194]loss : 0.0009260757942683995\n",
            "validation test finish\n",
            "validation :  81.58067374762885\n",
            "model saved\n",
            "epoch: 51\n",
            "epoch 51 [500/5194]loss : 0.0004665544256567955\n",
            "epoch 51 [1000/5194]loss : 0.0005717970198020339\n",
            "epoch 51 [1500/5194]loss : 0.0007870234549045563\n",
            "epoch 51 [2000/5194]loss : 0.00043126472155563533\n",
            "epoch 51 [2500/5194]loss : 0.0005257541197352111\n",
            "epoch 51 [3000/5194]loss : 0.0005132815567776561\n",
            "epoch 51 [3500/5194]loss : 0.0010224116267636418\n",
            "epoch 51 [4000/5194]loss : 0.0006897820858284831\n",
            "epoch 51 [4500/5194]loss : 0.0008043921552598476\n",
            "epoch 51 [5000/5194]loss : 0.00046990817645564675\n",
            "validation test finish\n",
            "validation :  81.22539513542985\n",
            "model saved\n",
            "epoch: 52\n",
            "epoch 52 [500/5194]loss : 0.0007655741646885872\n",
            "epoch 52 [1000/5194]loss : 0.0005517277168110013\n",
            "epoch 52 [1500/5194]loss : 0.0006471627857536077\n",
            "epoch 52 [2000/5194]loss : 0.0006169092375785112\n",
            "epoch 52 [2500/5194]loss : 0.0005827090935781598\n",
            "epoch 52 [3000/5194]loss : 0.0006014975951984525\n",
            "epoch 52 [3500/5194]loss : 0.0005994201055727899\n",
            "epoch 52 [4000/5194]loss : 0.0004371014656499028\n",
            "epoch 52 [4500/5194]loss : 0.0010370629606768489\n",
            "epoch 52 [5000/5194]loss : 0.0006432702066376805\n",
            "validation test finish\n",
            "validation :  81.33036225596788\n",
            "model saved\n",
            "epoch: 53\n",
            "epoch 53 [500/5194]loss : 0.0006244648830033839\n",
            "epoch 53 [1000/5194]loss : 0.0008375789620913565\n",
            "epoch 53 [1500/5194]loss : 0.0004059286438859999\n",
            "epoch 53 [2000/5194]loss : 0.000811129342764616\n",
            "epoch 53 [2500/5194]loss : 0.0005523038562387228\n",
            "epoch 53 [3000/5194]loss : 0.0007732654339633882\n",
            "epoch 53 [3500/5194]loss : 0.0009309813613072038\n",
            "epoch 53 [4000/5194]loss : 0.0005204532062634826\n",
            "epoch 53 [4500/5194]loss : 0.0006010879296809435\n",
            "epoch 53 [5000/5194]loss : 0.0005064593278802931\n",
            "validation test finish\n",
            "validation :  81.42217067822612\n",
            "model saved\n",
            "epoch: 54\n",
            "epoch 54 [500/5194]loss : 0.0006466112099587917\n",
            "epoch 54 [1000/5194]loss : 0.0006691704038530588\n",
            "epoch 54 [1500/5194]loss : 0.0005237391451373696\n",
            "epoch 54 [2000/5194]loss : 0.0004389240639284253\n",
            "epoch 54 [2500/5194]loss : 0.0003191356372553855\n",
            "epoch 54 [3000/5194]loss : 0.00041601608972996473\n",
            "epoch 54 [3500/5194]loss : 0.0005707129603251815\n",
            "epoch 54 [4000/5194]loss : 0.0006501948228105903\n",
            "epoch 54 [4500/5194]loss : 0.0008396592456847429\n",
            "epoch 54 [5000/5194]loss : 0.00038719509029760957\n",
            "validation test finish\n",
            "validation :  81.45955399848141\n",
            "model saved\n",
            "epoch: 55\n",
            "epoch 55 [500/5194]loss : 0.0003927148936782032\n",
            "epoch 55 [1000/5194]loss : 0.0004059209313709289\n",
            "epoch 55 [1500/5194]loss : 0.0003402050060685724\n",
            "epoch 55 [2000/5194]loss : 0.0005297714960761368\n",
            "epoch 55 [2500/5194]loss : 0.0009230764699168503\n",
            "epoch 55 [3000/5194]loss : 0.0004299025167711079\n",
            "epoch 55 [3500/5194]loss : 0.00037819836870767176\n",
            "epoch 55 [4000/5194]loss : 0.0006517845904454589\n",
            "epoch 55 [4500/5194]loss : 0.9600757956504822\n",
            "epoch 55 [5000/5194]loss : 0.0005939040565863252\n",
            "validation test finish\n",
            "validation :  81.90216598088577\n",
            "model saved\n",
            "epoch: 56\n",
            "epoch 56 [500/5194]loss : 0.0008169416105374694\n",
            "epoch 56 [1000/5194]loss : 0.0008446787251159549\n",
            "epoch 56 [1500/5194]loss : 0.0006080708699300885\n",
            "epoch 56 [2000/5194]loss : 0.00042061536805704236\n",
            "epoch 56 [2500/5194]loss : 0.00033036101376637816\n",
            "epoch 56 [3000/5194]loss : 0.0002770224818959832\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-8b3bebd85933>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mlr_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# 정의해둔 train 함수에 파라미터를 입력해 학습 진행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-44-b96c6f510ad4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(num_epochs, model, device, train_loader, val_loader, images, texts, lengths, converter, optimizer, lr_scheduler, prediction_dir, print_iter)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatas\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mdatas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-28a44adffe73>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# 이미지 모드 변경. 흰 배경에 검은 글씨 뿐이므로 그레이 스케일('L') 지정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'L'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2842\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2843\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2844\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# 다른 모델로 테스트시 변경\n",
        "# new_model = CRNN(imgH, nc, nclass, 256)\n",
        "# new_model.apply(weights_init)\n",
        "\n",
        "# mode == 'train'\n",
        "print('train start')\n",
        "params = [p for p in new_model.parameters() if p.requires_grad]\n",
        "optimizer = optim.Adam(params, lr=lr, betas=(0.5, 0.999))\n",
        "lr_scheduler = optim.lr_scheduler.StepLR(optimizer,step_size=40,gamma=0.1)\n",
        "# 정의해둔 train 함수에 파라미터를 입력해 학습 진행\n",
        "train(num_epochs, new_model, device, train_loader, val_loader, images, texts, lengths, converter, optimizer, lr_scheduler, prediction_dir, print_iter)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78790f54-745b-40ef-bf4f-aadcbf98ea8e",
      "metadata": {
        "id": "78790f54-745b-40ef-bf4f-aadcbf98ea8e"
      },
      "source": [
        "## 추론"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f081387d-453c-4a46-81cf-0c53409a4051",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f081387d-453c-4a46-81cf-0c53409a4051",
        "outputId": "57c24d8a-85eb-4320-98f3-222daf3802fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test start\n",
            "model loaded\n"
          ]
        }
      ],
      "source": [
        "print('test start')\n",
        "test_dataset = CustomDataset(DATASET_PATH, phase='test')\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch, shuffle=False, collate_fn=alignCollate(imgH=imgH, imgW=imgW))\n",
        "\n",
        "model_name = '55'\n",
        "load_model(model_name, new_model)\n",
        "\n",
        "# 정의해둔 test 함수에 파라미터를 입력해 추론 진행\n",
        "test_imgs, test_preds = test(new_model, device, test_loader, images, texts, lengths, converter, prediction_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c872fa02-3174-4a7a-8d24-74c9983872ce",
      "metadata": {
        "id": "c872fa02-3174-4a7a-8d24-74c9983872ce"
      },
      "outputs": [],
      "source": [
        "# 제출 결과 저장\n",
        "submit = pd.DataFrame(columns = ['file_name','text'])\n",
        "for i,img in enumerate(test_imgs):\n",
        "    submit.loc[len(submit)] = [img.split('/')[-1], test_preds[i]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f59e9fda-3b27-447f-8295-8f854666a6f6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f59e9fda-3b27-447f-8295-8f854666a6f6",
        "outputId": "d71b3432-3209-4be6-f915-ce8b06a83cc1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         file_name                                    text\n",
              "1072  00106736.png   톱스타 원빈이 낮 27일 일본 요코국마에서 라선 팬미팅을 연다. 한\n",
              "1073  00106737.png  빈을 이날 보코와마의 파시피크 중에서 재난행사 조 28a)'가 y5휘\n",
              "1074  00106760.png   는 이번 탐방은 만중은 의사 단련 레포드 국수 대학분 0명, 전국국\n",
              "1075  00106778.png                      줬다는 지의 발언을 한 인 있다.\n",
              "1076  00106779.png   대구지법 게 2형사부 1재판장 김종을 부보판사)는 1일 생활고로 남"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-422408cc-f43b-4650-a84f-b2269d74fd17\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1072</th>\n",
              "      <td>00106736.png</td>\n",
              "      <td>톱스타 원빈이 낮 27일 일본 요코국마에서 라선 팬미팅을 연다. 한</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1073</th>\n",
              "      <td>00106737.png</td>\n",
              "      <td>빈을 이날 보코와마의 파시피크 중에서 재난행사 조 28a)'가 y5휘</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1074</th>\n",
              "      <td>00106760.png</td>\n",
              "      <td>는 이번 탐방은 만중은 의사 단련 레포드 국수 대학분 0명, 전국국</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1075</th>\n",
              "      <td>00106778.png</td>\n",
              "      <td>줬다는 지의 발언을 한 인 있다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1076</th>\n",
              "      <td>00106779.png</td>\n",
              "      <td>대구지법 게 2형사부 1재판장 김종을 부보판사)는 1일 생활고로 남</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-422408cc-f43b-4650-a84f-b2269d74fd17')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-422408cc-f43b-4650-a84f-b2269d74fd17 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-422408cc-f43b-4650-a84f-b2269d74fd17');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "submit.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f01d96c4-f26b-4e4c-8093-36bf40a6aabc",
      "metadata": {
        "id": "f01d96c4-f26b-4e4c-8093-36bf40a6aabc"
      },
      "outputs": [],
      "source": [
        "# 제출 파일 제작\n",
        "submit.to_csv('/content/gdrive/MyDrive/sample/handwritten/pred.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Korean_handwritten_detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}